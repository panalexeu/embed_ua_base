{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525e7ec4-a479-48ce-80c6-58422aa2444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q mteb\n",
    "!uv pip install -q sentence-transformers\n",
    "!uv pip install -q pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720cff8d-3fb2-4579-a769-c4baf093a660",
   "metadata": {},
   "source": [
    "### Post-train Research\n",
    "\n",
    "In this notebook, some inference tests and benchmarking of the fine-tuned and original models are performed. \n",
    "\n",
    "One of the benchmarks is STS-17 in the following configurations: en-en, en-ua (machine translated), ua-ua (machine translated). \n",
    "\n",
    "The machine translation of the STS-17 benchmark to the Ukrainian language was performed in this [notebook](../dataset_translation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2dd1c9-bb66-4d12-afbf-0f527fcca7aa",
   "metadata": {},
   "source": [
    "#### Loading the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb03e91-d904-4ed5-8c24-f31b2c95b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name FacebookAI/xlm-roberta-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "# original \n",
    "xlm_roberta = SentenceTransformer('FacebookAI/xlm-roberta-base')\n",
    "xlm_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92453756-b328-47bc-9014-1e10a6af9d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tuned \n",
    "xlm_roberta_ua_distilled = SentenceTransformer('panalexeu/xlm-roberta-ua-distilled')\n",
    "xlm_roberta_ua_distilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09c6cf02-cdce-43ae-acc9-61c700ba7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assure that the models have identical configurations \n",
    "assert xlm_roberta[0].get_config_dict() == xlm_roberta_ua_distilled[0].get_config_dict()\n",
    "assert xlm_roberta[1].get_config_dict() == xlm_roberta_ua_distilled[1].get_config_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8502c9-c755-4e5b-bd96-6d679f7695de",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761730af-db2b-4e3f-be6f-553e985542fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SequentialEvaluator \n",
    "\n",
    "# STS Benchmark (Semantic Textual Similarity Benchmark)\n",
    "en_en_dataset = load_dataset('mteb/sts17-crosslingual-sts', 'en-en', split='test')\n",
    "en_ua_dataset = load_dataset('csv', data_files='../datasets/sts17-en-ua-gpt-4o.csv', split='train') # when loading from csv by default train split is assigned\n",
    "ua_ua_dataset = load_dataset('csv', data_files='../datasets/sts17-ua-ua-gpt-4o.csv', split='train')  # when loading from csv by default train split is assigned\n",
    "\n",
    "# From documentation: Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation in comparison to the gold standard labels. \n",
    "en_en_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_en_dataset['sentence1'],\n",
    "    sentences2=en_en_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_en_dataset['score']],  # normalizing to score from to 1\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-en',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "en_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_ua_dataset['sentence1'],\n",
    "    sentences2=en_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "ua_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=ua_ua_dataset['sentence1'],\n",
    "    sentences2=ua_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in ua_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-ua-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Composing evaluators in one chain! \n",
    "evaluator = SequentialEvaluator([en_en_eval, en_ua_eval, ua_ua_eval]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206a3a6-e662-4715-9afe-189efc3bd092",
   "metadata": {},
   "source": [
    "**Original** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8121c4c4-d1a7-4a9f-8f0a-df157093037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <th>eval_sts17-en-en_pearson_cosine</th>\n",
       "      <th>eval_sts17-en-en_spearman_cosine</th>\n",
       "      <th>eval_sts17-en-ua_pearson_cosine</th>\n",
       "      <th>eval_sts17-en-ua_spearman_cosine</th>\n",
       "      <th>eval_sts17-ua-ua_pearson_cosine</th>\n",
       "      <th>eval_sts17-ua-ua_spearman_cosine</th>\n",
       "      <th>eval_sequential_score</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.361103</td>\n",
       "      <td>0.521713</td>\n",
       "      <td>0.128055</td>\n",
       "      <td>0.134548</td>\n",
       "      <td>0.302439</td>\n",
       "      <td>0.415173</td>\n",
       "      <td>0.415173</td>\n",
       "      <td>1.9056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_model_preparation_time  eval_sts17-en-en_pearson_cosine  \\\n",
       "0                       0.0018                         0.361103   \n",
       "\n",
       "   eval_sts17-en-en_spearman_cosine  eval_sts17-en-ua_pearson_cosine  \\\n",
       "0                          0.521713                         0.128055   \n",
       "\n",
       "   eval_sts17-en-ua_spearman_cosine  eval_sts17-ua-ua_pearson_cosine  \\\n",
       "0                          0.134548                         0.302439   \n",
       "\n",
       "   eval_sts17-ua-ua_spearman_cosine  eval_sequential_score  eval_runtime  \\\n",
       "0                          0.415173               0.415173        1.9056   \n",
       "\n",
       "   eval_samples_per_second  eval_steps_per_second  \n",
       "0                      0.0                    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "res = SentenceTransformerTrainer(\n",
    "    model=xlm_roberta,\n",
    "    evaluator=evaluator\n",
    ").evaluate()\n",
    "\n",
    "pd.DataFrame([res])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb427c7-b582-49e8-8e8e-9a25d768bc77",
   "metadata": {},
   "source": [
    "**Distilled and fine-tuned** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99fdbe8-9090-4127-9b78-e20e435bbf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_model_preparation_time</th>\n",
       "      <th>eval_sts17-en-en_pearson_cosine</th>\n",
       "      <th>eval_sts17-en-en_spearman_cosine</th>\n",
       "      <th>eval_sts17-en-ua_pearson_cosine</th>\n",
       "      <th>eval_sts17-en-ua_spearman_cosine</th>\n",
       "      <th>eval_sts17-ua-ua_pearson_cosine</th>\n",
       "      <th>eval_sts17-ua-ua_spearman_cosine</th>\n",
       "      <th>eval_sequential_score</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.678482</td>\n",
       "      <td>0.730849</td>\n",
       "      <td>0.592555</td>\n",
       "      <td>0.619761</td>\n",
       "      <td>0.6159</td>\n",
       "      <td>0.644575</td>\n",
       "      <td>0.644575</td>\n",
       "      <td>1.7701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_model_preparation_time  eval_sts17-en-en_pearson_cosine  \\\n",
       "0                       0.0018                         0.678482   \n",
       "\n",
       "   eval_sts17-en-en_spearman_cosine  eval_sts17-en-ua_pearson_cosine  \\\n",
       "0                          0.730849                         0.592555   \n",
       "\n",
       "   eval_sts17-en-ua_spearman_cosine  eval_sts17-ua-ua_pearson_cosine  \\\n",
       "0                          0.619761                           0.6159   \n",
       "\n",
       "   eval_sts17-ua-ua_spearman_cosine  eval_sequential_score  eval_runtime  \\\n",
       "0                          0.644575               0.644575        1.7701   \n",
       "\n",
       "   eval_samples_per_second  eval_steps_per_second  \n",
       "0                      0.0                    0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "res = SentenceTransformerTrainer(\n",
    "    model=xlm_roberta_ua_distilled,\n",
    "    evaluator=evaluator\n",
    ").evaluate()\n",
    "\n",
    "pd.DataFrame([res])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4afff-9996-44ea-9435-40b04916beb8",
   "metadata": {},
   "source": [
    "#### Minimal test on quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cce7ada-bf00-4fed-99d3-e55b9db9eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    \"An idiot admires complexity, a genius admires simplicity.\",          # English\n",
    "    \"Ідіот захоплюється складністю, геній — простотою.\",                  # Ukrainian\n",
    "]\n",
    "\n",
    "quotes_antonyms = [\n",
    "    \"Hello, World!\",\n",
    "    \"Прощавай, Місяць.\"\n",
    "]\n",
    "\n",
    "# to check zero-shot crosslingual transfer effect \n",
    "quotes_extended = quotes + [\n",
    "    \"Идиот восхищается сложностью, гений — простотой.\",                   # Russian\n",
    "    \"Ідыёт захапляецца складанасцю, геній — прастатой.\",                  # Belarusian\n",
    "    \"Идиот се възхищава на сложността, гений — на простотата.\"            # Bulgarian\n",
    "]\n",
    "# P.S. I love Terry Davis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a4b48-90aa-459c-945b-bf2801c32b12",
   "metadata": {},
   "source": [
    "**Close quotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e16f14-964d-4ca8-8a15-c25ecd648ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9967],\n",
       "        [0.9967, 1.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta.encode(quotes)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a64b4f5-6959-4dba-a090-368ecf75f053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9446],\n",
       "        [0.9446, 1.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7b445-5c78-455a-affe-9447a6ce7dc8",
   "metadata": {},
   "source": [
    "**Antonyms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f406ee-1022-4762-bd0c-2f0377d2691e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9867],\n",
       "        [0.9867, 1.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta.encode(quotes_antonyms)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "320aeadb-fba2-4567-b336-41559dfbebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7311],\n",
       "        [0.7311, 1.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes_antonyms)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9e7fb-debd-496b-9640-43351acc6d89",
   "metadata": {},
   "source": [
    "**Zero-shot cross-lingual transfer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2dd7577-ff74-431a-a28d-57fbbeccf675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9967, 0.9970, 0.9958, 0.9964],\n",
       "        [0.9967, 1.0000, 0.9983, 0.9971, 0.9978],\n",
       "        [0.9970, 0.9983, 1.0000, 0.9970, 0.9987],\n",
       "        [0.9958, 0.9971, 0.9970, 1.0000, 0.9964],\n",
       "        [0.9964, 0.9978, 0.9987, 0.9964, 1.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta.encode(quotes_extended)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54608e64-d595-4c4a-a66e-56460a90f651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9446, 0.9264, 0.9150, 0.9338],\n",
       "        [0.9446, 1.0000, 0.9342, 0.9505, 0.9434],\n",
       "        [0.9264, 0.9342, 1.0000, 0.9301, 0.9913],\n",
       "        [0.9150, 0.9505, 0.9301, 1.0000, 0.9309],\n",
       "        [0.9338, 0.9434, 0.9913, 0.9309, 1.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes_extended)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_ua_base",
   "language": "python",
   "name": "embed_ua_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
