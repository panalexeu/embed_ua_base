{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "527b35f8-2758-4a09-83df-a09d95c9c4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -qU sentence-transformers\n",
    "!uv pip install -q transformers\n",
    "!uv pip install -q datasets \n",
    "!uv pip install -q ipywidgets\n",
    "!uv pip install -q pandas \n",
    "!uv pip install -q accelerate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c691e-e582-4caf-9bf4-66c32eb40783",
   "metadata": {},
   "source": [
    "### Research\n",
    "\n",
    "In the provided notebook, research will be conducted on the performance and methods for fine-tuning a local, open-source embedding model to achieve better performance in the Ukrainian language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65adf5a-76bd-4af7-8719-7c7fe0dcfaef",
   "metadata": {},
   "source": [
    "### Multilingual Distillation\n",
    "\n",
    "We will start by researching the approach proposed in the following [research paper](https://arxiv.org/pdf/2004.09813). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba06ab5-c15f-486f-a15c-ad43484c894e",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f694e3-a7dc-4f4e-83eb-e6d31854021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['english', 'non_english'],\n",
       "        num_rows: 993\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['english', 'non_english'],\n",
       "        num_rows: 201883\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('sentence-transformers/parallel-sentences-talks', 'en-uk')\n",
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8767714-3dd8-4c20-a0e8-fccbdc42ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "train_dataset.set_format(type='pandas')\n",
    "train_df = train_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75082a9f-c522-4f8c-92f5-f9ea7a85455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201883 entries, 0 to 201882\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   english      201883 non-null  object\n",
      " 1   non_english  201883 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394b0dcd-f591-4d40-a348-06a0b2727e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>non_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want you to know that I believe kids will ea...</td>\n",
       "      <td>Я хочу, щоб ви знали, що я впевнений що діти б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want you to know that there are farmers' mar...</td>\n",
       "      <td>Я хочу, щоб ви знали, що є фермерські ринки як...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want you to know that me, my brother and sis...</td>\n",
       "      <td>Я хочу, щоб ви знали, що я, мої брат та сестра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I try to share this everywhere I go.</td>\n",
       "      <td>Я намагаюся поділитися цим всюди, куди б я не ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not too long ago, my uncle said that he offere...</td>\n",
       "      <td>Не так давно, мій дядько сказав, що він запроп...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  I want you to know that I believe kids will ea...   \n",
       "1  I want you to know that there are farmers' mar...   \n",
       "2  I want you to know that me, my brother and sis...   \n",
       "3               I try to share this everywhere I go.   \n",
       "4  Not too long ago, my uncle said that he offere...   \n",
       "\n",
       "                                         non_english  \n",
       "0  Я хочу, щоб ви знали, що я впевнений що діти б...  \n",
       "1  Я хочу, щоб ви знали, що є фермерські ринки як...  \n",
       "2  Я хочу, щоб ви знали, що я, мої брат та сестра...  \n",
       "3  Я намагаюся поділитися цим всюди, куди б я не ...  \n",
       "4  Не так давно, мій дядько сказав, що він запроп...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65a3436-0668-40a1-9e13-630a0741e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset df format\n",
    "train_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786b16b4-6410-477d-9469-76cfedc6feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = dataset['dev']\n",
    "eval_dataset.set_format(type='pandas')\n",
    "eval_df = eval_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8213831-fcb0-4e11-ba9c-0d8bb4a2e13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 993 entries, 0 to 992\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   english      993 non-null    object\n",
      " 1   non_english  993 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.6+ KB\n"
     ]
    }
   ],
   "source": [
    "eval_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ed62878-8d30-4c07-a1f2-fc162847d8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>non_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you so much, Chris.</td>\n",
       "      <td>Дуже дякую, Кріс!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And it's truly a great honor to have the oppor...</td>\n",
       "      <td>Справді, для мене це велика честь мати можливі...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been blown away by this conference, and...</td>\n",
       "      <td>Я в захваті від цієї конференції, і я хочу под...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And I say that sincerely, partly because (Mock...</td>\n",
       "      <td>І, щиро кажучи, частково тому що – (Схлипує) –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Laughter) Put yourselves in my position.</td>\n",
       "      <td>(Сміх) Поставте себе на моє місце!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0                          Thank you so much, Chris.   \n",
       "1  And it's truly a great honor to have the oppor...   \n",
       "2  I have been blown away by this conference, and...   \n",
       "3  And I say that sincerely, partly because (Mock...   \n",
       "4          (Laughter) Put yourselves in my position.   \n",
       "\n",
       "                                         non_english  \n",
       "0                                  Дуже дякую, Кріс!  \n",
       "1  Справді, для мене це велика честь мати можливі...  \n",
       "2  Я в захваті від цієї конференції, і я хочу под...  \n",
       "3  І, щиро кажучи, частково тому що – (Схлипує) –...  \n",
       "4                 (Сміх) Поставте себе на моє місце!  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46a8adea-6635-4681-8403-76a629695bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset df format\n",
    "eval_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdfcd19-75ec-470f-9650-4c25e7ae4bac",
   "metadata": {},
   "source": [
    "### Load teacher and student model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c8d9c3-9267-422c-8114-9463aeafc932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import Transformer, Pooling \n",
    "\n",
    "teacher_model_id = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
    "transformer_module = Transformer(teacher_model_id, model_args=dict(torch_dtype=torch.float32))\n",
    "pooling_module = Pooling(\n",
    "    word_embedding_dimension=transformer_module.get_word_embedding_dimension(),\n",
    "    pooling_mode_cls_token=True,\n",
    "    pooling_mode_mean_tokens=False\n",
    ")\n",
    "teacher_model = SentenceTransformer(modules=[transformer_module, pooling_module])\n",
    "teacher_model.to('cuda')\n",
    "teacher_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897d2f02-b2dd-4548-a08d-1744580df0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model[0].auto_model.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b32665-f467-4d7f-8591-ce2856ae4b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import Transformer, Pooling \n",
    "\n",
    "student_model_id = 'FacebookAI/xlm-roberta-base'\n",
    "transformer_module = Transformer(student_model_id, model_args=dict(torch_dtype=torch.float32))\n",
    "pooling_module = Pooling(\n",
    "    word_embedding_dimension=transformer_module.get_word_embedding_dimension(),\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "student_model = SentenceTransformer(modules=[transformer_module, pooling_module])\n",
    "student_model.to('cuda')\n",
    "student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a928f52-4a34-4815-8bbd-da9538f93d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model[0].auto_model.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9afea1cb-de43-4404-988a-f7f03332b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that transformer config matched for student and teacher model\n",
    "assert student_model[0].get_config_dict() == teacher_model[0].get_config_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1211b-e0e8-4347-bfc0-0f775cf959f6",
   "metadata": {},
   "source": [
    "### Dtaset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "128252d3-ab63-4df2-ab33-a02b302c4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    return {\n",
    "        'english': batch['english'],\n",
    "        'non_english': batch['non_english'],\n",
    "        'label': teacher_model.encode(batch['english'], padding=True, truncation=True, precision='float32')\n",
    "   } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60d798c2-710c-4d6c-a703-6adac5a1addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7967a350989b4e958b50997855aacb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/201883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_labeled = train_dataset.map(prepare_dataset, batched=True, batch_size=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35f3cc3-44f1-4f3a-9fd3-c3828cd5f7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['english', 'non_english', 'label'],\n",
       "    num_rows: 201883\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b66e9e6-43cb-477c-b3af-9e0999d1e1d2",
   "metadata": {},
   "source": [
    "### Defining loss function and evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "381e0727-849b-4305-9430-81e19ae76acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers.losses import MSELoss\n",
    "\n",
    "# Computes loss between computed sentence embeddings by student ('english' and 'non_english') and target computed by teacher ('label') \n",
    "mse_loss = MSELoss(model=student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d0717f5-6b1a-433f-9f73-48bf55f955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import MSEEvaluator, EmbeddingSimilarityEvaluator, SequentialEvaluator \n",
    "\n",
    "# From documentation: The MSE is computed between ||teacher.encode(source_sentences) - student.encode(target_sentences)||.\n",
    "mse_eval = MSEEvaluator(\n",
    "    source_sentences=eval_dataset['english'],\n",
    "    target_sentences=eval_dataset['non_english'],\n",
    "    name='mse-en-ua',\n",
    "    teacher_model=teacher_model,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# STS Benchmark (Semantic Textual Similarity Benchmark)\n",
    "en_en_dataset = load_dataset('mteb/sts17-crosslingual-sts', 'en-en', split='test')\n",
    "en_ua_dataset = load_dataset('csv', data_files='./datasets/sts17-en-ua-gpt-4o.csv', split='train') # when loading from csv by default train split is assigned\n",
    "ua_ua_dataset = load_dataset('csv', data_files='./datasets/sts17-ua-ua-gpt-4o.csv', split='train')  # when loading from csv by default train split is assigned\n",
    "\n",
    "# From documentation: Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation in comparison to the gold standard labels. \n",
    "en_en_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_en_dataset['sentence1'],\n",
    "    sentences2=en_en_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_en_dataset['score']],  # normalizing to score from to 1\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-en',\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "en_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_ua_dataset['sentence1'],\n",
    "    sentences2=en_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-ua',\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "ua_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=ua_ua_dataset['sentence1'],\n",
    "    sentences2=ua_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in ua_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-ua-ua',\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "# Composing evaluators in one chain! \n",
    "evaluator = SequentialEvaluator([mse_eval, en_en_eval, en_ua_eval, ua_ua_eval]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945bf48-78e3-47d2-adcd-9dad78b2bd45",
   "metadata": {},
   "source": [
    "### Defining training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf47ae4e-9185-41f8-923e-206e69c636d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "\n",
    "train_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir='./xlm-roberta-ua-distilled',\n",
    "    fp16=False,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "\n",
    "    eval_steps=4096, \n",
    "    eval_strategy='steps',\n",
    "\n",
    "    save_steps=4096, \n",
    "    save_strategy='steps',\n",
    "    save_total_limit=2,\n",
    "    \n",
    "    logging_steps=100 # change to 500 in future \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca03c3-114d-41f1-bf4f-0fff87d75d12",
   "metadata": {},
   "source": [
    "### Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e50a8598-395e-4898-ae79-d16b52ddcc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0591e93f5a34c41a4ae1c1c423ec79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=student_model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataset_labeled,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=mse_loss,\n",
    "    evaluator=evaluator \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "177b517f-e40e-487c-8e95-1000f0ae735c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 3.69 GiB of which 268.81 MiB is free. Including non-PyTorch memory, this process has 3.41 GiB memory in use. Of the allocated memory 3.21 GiB is allocated by PyTorch, and 104.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/embed_ua_base/.venv/lib/python3.9/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/embed_ua_base/.venv/lib/python3.9/site-packages/transformers/trainer.py:2611\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2607\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2611\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "File \u001b[0;32m~/python/embed_ua_base/.venv/lib/python3.9/site-packages/accelerate/optimizer.py:178\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/python/embed_ua_base/.venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/embed_ua_base/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/python/embed_ua_base/.venv/lib/python3.9/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/python/embed_ua_base/.venv/lib/python3.9/site-packages/torch/optim/adamw.py:232\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    229\u001b[0m     amsgrad: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    230\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 232\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     adamw(\n\u001b[1;32m    244\u001b[0m         params_with_grad,\n\u001b[1;32m    245\u001b[0m         grads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/python/embed_ua_base/.venv/lib/python3.9/site-packages/torch/optim/adamw.py:175\u001b[0m, in \u001b[0;36mAdamW._init_group\u001b[0;34m(self, group, params_with_grad, grads, amsgrad, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[1;32m    171\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\n\u001b[1;32m    172\u001b[0m     p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format\n\u001b[1;32m    173\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\n\u001b[1;32m    181\u001b[0m         p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format\n\u001b[1;32m    182\u001b[0m     )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 3.69 GiB of which 268.81 MiB is free. Including non-PyTorch memory, this process has 3.41 GiB memory in use. Of the allocated memory 3.21 GiB is allocated by PyTorch, and 104.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df51a4-9463-4aa1-a145-0f8ab97bc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683180a-ab74-43d1-826c-73fa8a6accc1",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d85a4-016d-4e44-914a-936ed498e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.save('./xlm-roberta-ua-distilled/final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_ua_base",
   "language": "python",
   "name": "embed_ua_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
