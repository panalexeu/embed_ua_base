{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525e7ec4-a479-48ce-80c6-58422aa2444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q mteb\n",
    "!uv pip install -q sentence-transformers\n",
    "!uv pip install -q pandas\n",
    "!uv pip install -q rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720cff8d-3fb2-4579-a769-c4baf093a660",
   "metadata": {},
   "source": [
    "### Post-train Research\n",
    "\n",
    "In this notebook, some inference tests and benchmarking of the fine-tuned and original models are performed. \n",
    "\n",
    "One of the benchmarks is STS-17 in the following configurations: en-en, en-ua (machine translated), ua-ua (machine translated). \n",
    "\n",
    "The machine translation of the STS-17 benchmark to the Ukrainian language was performed in this [notebook](../dataset_translation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2dd1c9-bb66-4d12-afbf-0f527fcca7aa",
   "metadata": {},
   "source": [
    "#### Loading the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb03e91-d904-4ed5-8c24-f31b2c95b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name FacebookAI/xlm-roberta-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "# original \n",
    "xlm_roberta = SentenceTransformer('FacebookAI/xlm-roberta-base')\n",
    "xlm_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92453756-b328-47bc-9014-1e10a6af9d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tuned \n",
    "xlm_roberta_ua_distilled = SentenceTransformer('panalexeu/xlm-roberta-ua-distilled')\n",
    "xlm_roberta_ua_distilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c6cf02-cdce-43ae-acc9-61c700ba7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assure that the models have identical configurations \n",
    "assert xlm_roberta[0].get_config_dict() == xlm_roberta_ua_distilled[0].get_config_dict()\n",
    "assert xlm_roberta[1].get_config_dict() == xlm_roberta_ua_distilled[1].get_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4467d423-d56e-4bd3-aabb-d9cf3991ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teacher model\n",
    "multi_qa_mpnet = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "multi_qa_mpnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8502c9-c755-4e5b-bd96-6d679f7695de",
   "metadata": {},
   "source": [
    "#### STS-17 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761730af-db2b-4e3f-be6f-553e985542fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SequentialEvaluator \n",
    "\n",
    "# STS Benchmark (Semantic Textual Similarity Benchmark)\n",
    "en_en_dataset = load_dataset('mteb/sts17-crosslingual-sts', 'en-en', split='test')\n",
    "en_ua_dataset = load_dataset('csv', data_files='../datasets/sts17-en-ua-gpt-4o.csv', split='train') # when loading from csv by default train split is assigned\n",
    "ua_ua_dataset = load_dataset('csv', data_files='../datasets/sts17-ua-ua-gpt-4o.csv', split='train')  # when loading from csv by default train split is assigned\n",
    "\n",
    "# From documentation: Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation in comparison to the gold standard labels. \n",
    "en_en_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_en_dataset['sentence1'],\n",
    "    sentences2=en_en_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_en_dataset['score']],  # normalizing to score from to 1\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-en',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "en_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_ua_dataset['sentence1'],\n",
    "    sentences2=en_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "ua_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=ua_ua_dataset['sentence1'],\n",
    "    sentences2=ua_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in ua_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-ua-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Composing evaluators in one chain! \n",
    "evaluator = SequentialEvaluator([en_en_eval, en_ua_eval, ua_ua_eval]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206a3a6-e662-4715-9afe-189efc3bd092",
   "metadata": {},
   "source": [
    "**Original** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8121c4c4-d1a7-4a9f-8f0a-df157093037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model_preparation_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0017</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.36110322291820246</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5217129934278466</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.12805525703810633</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.13454840278964744</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.302438933599461</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4151725913805182</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sequential_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4151725913805182</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.9079</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'eval_model_preparation_time'\u001b[0m: \u001b[1;36m0.0017\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_pearson_cosine'\u001b[0m: \u001b[1;36m0.36110322291820246\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_spearman_cosine'\u001b[0m: \u001b[1;36m0.5217129934278466\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.12805525703810633\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.13454840278964744\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.302438933599461\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.4151725913805182\u001b[0m,\n",
       "    \u001b[32m'eval_sequential_score'\u001b[0m: \u001b[1;36m0.4151725913805182\u001b[0m,\n",
       "    \u001b[32m'eval_runtime'\u001b[0m: \u001b[1;36m1.9079\u001b[0m,\n",
       "    \u001b[32m'eval_samples_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'eval_steps_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print \n",
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "res = SentenceTransformerTrainer(\n",
    "    model=xlm_roberta,\n",
    "    evaluator=evaluator\n",
    ").evaluate()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb427c7-b582-49e8-8e8e-9a25d768bc77",
   "metadata": {},
   "source": [
    "**Fine-tuned** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99fdbe8-9090-4127-9b78-e20e435bbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model_preparation_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0016</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6784819681712645</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7308493185913256</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5925553586829718</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6197606373137193</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6158998600027094</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6445750755380512</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sequential_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6445750755380512</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.7551</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'eval_model_preparation_time'\u001b[0m: \u001b[1;36m0.0016\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_pearson_cosine'\u001b[0m: \u001b[1;36m0.6784819681712645\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_spearman_cosine'\u001b[0m: \u001b[1;36m0.7308493185913256\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.5925553586829718\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.6197606373137193\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.6158998600027094\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.6445750755380512\u001b[0m,\n",
       "    \u001b[32m'eval_sequential_score'\u001b[0m: \u001b[1;36m0.6445750755380512\u001b[0m,\n",
       "    \u001b[32m'eval_runtime'\u001b[0m: \u001b[1;36m1.7551\u001b[0m,\n",
       "    \u001b[32m'eval_samples_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'eval_steps_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "res = SentenceTransformerTrainer(\n",
    "    model=xlm_roberta_ua_distilled,\n",
    "    evaluator=evaluator\n",
    ").evaluate()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294309f7-15bb-4b76-b138-33a4abe1e8d9",
   "metadata": {},
   "source": [
    "**multi-qa-mpnet-base-dot-v1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c874ed1-5005-4209-8eac-b6bb2206b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model_preparation_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0016</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7372436032190661</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7582948479414522</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17201717053290624</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1290184740058981</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5915510256143389</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6231217598535435</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sequential_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6231217598535435</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.663</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'eval_model_preparation_time'\u001b[0m: \u001b[1;36m0.0016\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_pearson_cosine'\u001b[0m: \u001b[1;36m0.7372436032190661\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_spearman_cosine'\u001b[0m: \u001b[1;36m0.7582948479414522\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.17201717053290624\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.1290184740058981\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.5915510256143389\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.6231217598535435\u001b[0m,\n",
       "    \u001b[32m'eval_sequential_score'\u001b[0m: \u001b[1;36m0.6231217598535435\u001b[0m,\n",
       "    \u001b[32m'eval_runtime'\u001b[0m: \u001b[1;36m2.663\u001b[0m,\n",
       "    \u001b[32m'eval_samples_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'eval_steps_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "res = SentenceTransformerTrainer(\n",
    "    model=multi_qa_mpnet,\n",
    "    evaluator=evaluator\n",
    ").evaluate()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf5460-2c04-47f8-8dbc-0a613b70e11d",
   "metadata": {},
   "source": [
    "Spearman scores table: \n",
    "\n",
    "| model                                | en-en | en-ua    | ua-ua    | \n",
    "| ------------------------------------ | ----- | -------- | -------- |  \n",
    "| multi-qa-mpnet-base-dot-v1           | 75.8  | 12.9     | 62.3     |\n",
    "| XLM-RoBERTa                          | 52.2  | 13.5     | 41.5     |\n",
    "| xlm-roberta-ua-distilled*            | 73.1  | **62.0** | **64.5** |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_ua_base",
   "language": "python",
   "name": "embed_ua_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
