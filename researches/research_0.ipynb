{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:50:50.376522Z",
     "iopub.status.busy": "2025-04-11T13:50:50.376176Z",
     "iopub.status.idle": "2025-04-11T13:51:05.697932Z",
     "shell.execute_reply": "2025-04-11T13:51:05.696994Z",
     "shell.execute_reply.started": "2025-04-11T13:50:50.376497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentence-transformers\n",
    "!pip install -q transformers\n",
    "!pip install -q datasets \n",
    "!pip install -q pandas \n",
    "!pip install -q accelerate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:51:36.802786Z",
     "iopub.status.busy": "2025-04-11T13:51:36.801953Z",
     "iopub.status.idle": "2025-04-11T13:51:38.250253Z",
     "shell.execute_reply": "2025-04-11T13:51:38.249289Z",
     "shell.execute_reply.started": "2025-04-11T13:51:36.802753Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qy wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:52:43.942812Z",
     "iopub.status.busy": "2025-04-11T13:52:43.942472Z",
     "iopub.status.idle": "2025-04-11T13:52:44.258609Z",
     "shell.execute_reply": "2025-04-11T13:52:44.258026Z",
     "shell.execute_reply.started": "2025-04-11T13:52:43.942785Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "train_dataset.set_format(type='pandas')\n",
    "train_df = train_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:05:52.368134Z",
     "iopub.status.busy": "2025-04-11T09:05:52.367849Z",
     "iopub.status.idle": "2025-04-11T09:05:52.440699Z",
     "shell.execute_reply": "2025-04-11T09:05:52.439933Z",
     "shell.execute_reply.started": "2025-04-11T09:05:52.368110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 201883 entries, 0 to 201882\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   english      201883 non-null  object\n",
      " 1   non_english  201883 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:05:52.441835Z",
     "iopub.status.busy": "2025-04-11T09:05:52.441605Z",
     "iopub.status.idle": "2025-04-11T09:05:52.462051Z",
     "shell.execute_reply": "2025-04-11T09:05:52.461483Z",
     "shell.execute_reply.started": "2025-04-11T09:05:52.441816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>non_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want you to know that I believe kids will ea...</td>\n",
       "      <td>Я хочу, щоб ви знали, що я впевнений що діти б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want you to know that there are farmers' mar...</td>\n",
       "      <td>Я хочу, щоб ви знали, що є фермерські ринки як...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want you to know that me, my brother and sis...</td>\n",
       "      <td>Я хочу, щоб ви знали, що я, мої брат та сестра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I try to share this everywhere I go.</td>\n",
       "      <td>Я намагаюся поділитися цим всюди, куди б я не ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not too long ago, my uncle said that he offere...</td>\n",
       "      <td>Не так давно, мій дядько сказав, що він запроп...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  I want you to know that I believe kids will ea...   \n",
       "1  I want you to know that there are farmers' mar...   \n",
       "2  I want you to know that me, my brother and sis...   \n",
       "3               I try to share this everywhere I go.   \n",
       "4  Not too long ago, my uncle said that he offere...   \n",
       "\n",
       "                                         non_english  \n",
       "0  Я хочу, щоб ви знали, що я впевнений що діти б...  \n",
       "1  Я хочу, щоб ви знали, що є фермерські ринки як...  \n",
       "2  Я хочу, щоб ви знали, що я, мої брат та сестра...  \n",
       "3  Я намагаюся поділитися цим всюди, куди б я не ...  \n",
       "4  Не так давно, мій дядько сказав, що він запроп...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:05:52.463008Z",
     "iopub.status.busy": "2025-04-11T09:05:52.462774Z",
     "iopub.status.idle": "2025-04-11T09:05:52.467189Z",
     "shell.execute_reply": "2025-04-11T09:05:52.466367Z",
     "shell.execute_reply.started": "2025-04-11T09:05:52.462979Z"
    }
   },
   "outputs": [],
   "source": [
    "# reset df format\n",
    "train_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:05:52.468368Z",
     "iopub.status.busy": "2025-04-11T09:05:52.468018Z",
     "iopub.status.idle": "2025-04-11T09:05:52.483001Z",
     "shell.execute_reply": "2025-04-11T09:05:52.482318Z",
     "shell.execute_reply.started": "2025-04-11T09:05:52.468338Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_dataset = dataset['dev']\n",
    "eval_dataset.set_format(type='pandas')\n",
    "eval_df = eval_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:05:52.483992Z",
     "iopub.status.busy": "2025-04-11T09:05:52.483766Z",
     "iopub.status.idle": "2025-04-11T09:05:52.501492Z",
     "shell.execute_reply": "2025-04-11T09:05:52.500614Z",
     "shell.execute_reply.started": "2025-04-11T09:05:52.483968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 993 entries, 0 to 992\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   english      993 non-null    object\n",
      " 1   non_english  993 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.6+ KB\n"
     ]
    }
   ],
   "source": [
    "eval_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:05:52.504371Z",
     "iopub.status.busy": "2025-04-11T09:05:52.504117Z",
     "iopub.status.idle": "2025-04-11T09:05:52.520012Z",
     "shell.execute_reply": "2025-04-11T09:05:52.519303Z",
     "shell.execute_reply.started": "2025-04-11T09:05:52.504353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>non_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you so much, Chris.</td>\n",
       "      <td>Дуже дякую, Кріс!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And it's truly a great honor to have the oppor...</td>\n",
       "      <td>Справді, для мене це велика честь мати можливі...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been blown away by this conference, and...</td>\n",
       "      <td>Я в захваті від цієї конференції, і я хочу под...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And I say that sincerely, partly because (Mock...</td>\n",
       "      <td>І, щиро кажучи, частково тому що – (Схлипує) –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Laughter) Put yourselves in my position.</td>\n",
       "      <td>(Сміх) Поставте себе на моє місце!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0                          Thank you so much, Chris.   \n",
       "1  And it's truly a great honor to have the oppor...   \n",
       "2  I have been blown away by this conference, and...   \n",
       "3  And I say that sincerely, partly because (Mock...   \n",
       "4          (Laughter) Put yourselves in my position.   \n",
       "\n",
       "                                         non_english  \n",
       "0                                  Дуже дякую, Кріс!  \n",
       "1  Справді, для мене це велика честь мати можливі...  \n",
       "2  Я в захваті від цієї конференції, і я хочу под...  \n",
       "3  І, щиро кажучи, частково тому що – (Схлипує) –...  \n",
       "4                 (Сміх) Поставте себе на моє місце!  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:05:52.521067Z",
     "iopub.status.busy": "2025-04-11T09:05:52.520833Z",
     "iopub.status.idle": "2025-04-11T09:05:52.533926Z",
     "shell.execute_reply": "2025-04-11T09:05:52.533179Z",
     "shell.execute_reply.started": "2025-04-11T09:05:52.521041Z"
    }
   },
   "outputs": [],
   "source": [
    "# reset df format\n",
    "eval_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load teacher and student model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:05:52.534905Z",
     "iopub.status.busy": "2025-04-11T09:05:52.534682Z",
     "iopub.status.idle": "2025-04-11T09:06:23.916736Z",
     "shell.execute_reply": "2025-04-11T09:06:23.915914Z",
     "shell.execute_reply.started": "2025-04-11T09:05:52.534881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 09:06:05.307885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744362365.543760      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744362365.612423      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e475f6f49854780a480506116195f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc85a5c7a31845658c6370767968945f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0c1db8558146d99823b4c48fb33b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa47657cc2f946ff98aae24e5df083e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69606d2608f4b9389610ec6c5e9450e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f950821718b4dbeae616b230016c8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import Transformer, Pooling \n",
    "\n",
    "teacher_model_id = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n",
    "transformer_module = Transformer(teacher_model_id, model_args=dict(torch_dtype=torch.float32))\n",
    "pooling_module = Pooling(\n",
    "    word_embedding_dimension=transformer_module.get_word_embedding_dimension(),\n",
    "    pooling_mode_cls_token=False,  # initiall True is here \n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "teacher_model = SentenceTransformer(modules=[transformer_module, pooling_module])\n",
    "teacher_model.to('cuda')\n",
    "teacher_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:06:23.918708Z",
     "iopub.status.busy": "2025-04-11T09:06:23.917614Z",
     "iopub.status.idle": "2025-04-11T09:06:23.923267Z",
     "shell.execute_reply": "2025-04-11T09:06:23.922486Z",
     "shell.execute_reply.started": "2025-04-11T09:06:23.918686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model[0].auto_model.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:06:23.924186Z",
     "iopub.status.busy": "2025-04-11T09:06:23.923920Z",
     "iopub.status.idle": "2025-04-11T09:06:31.735800Z",
     "shell.execute_reply": "2025-04-11T09:06:31.735180Z",
     "shell.execute_reply.started": "2025-04-11T09:06:23.924157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9139ed40234df0b7350a6a6a0e9971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7444bb402fb2473199f9a7a54eb608a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8b2a4d90b64d7396ead5406427f71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd779019ee2f4114bf075783b8f53d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c303287299ee441fb1f1bcf688ebe6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.models import Transformer, Pooling \n",
    "\n",
    "student_model_id = 'FacebookAI/xlm-roberta-base'\n",
    "transformer_module = Transformer(student_model_id, model_args=dict(torch_dtype=torch.float32))\n",
    "pooling_module = Pooling(\n",
    "    word_embedding_dimension=transformer_module.get_word_embedding_dimension(),\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "student_model = SentenceTransformer(modules=[transformer_module, pooling_module])\n",
    "student_model.to('cuda')\n",
    "student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:06:31.737179Z",
     "iopub.status.busy": "2025-04-11T09:06:31.736593Z",
     "iopub.status.idle": "2025-04-11T09:06:31.742374Z",
     "shell.execute_reply": "2025-04-11T09:06:31.741458Z",
     "shell.execute_reply.started": "2025-04-11T09:06:31.737132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model[0].auto_model.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:06:31.743784Z",
     "iopub.status.busy": "2025-04-11T09:06:31.743467Z",
     "iopub.status.idle": "2025-04-11T09:06:32.146751Z",
     "shell.execute_reply": "2025-04-11T09:06:32.145936Z",
     "shell.execute_reply.started": "2025-04-11T09:06:31.743756Z"
    }
   },
   "outputs": [],
   "source": [
    "# assert that transformer config matched for student and teacher model\n",
    "assert student_model[0].get_config_dict() == teacher_model[0].get_config_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dtaset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:06:32.147801Z",
     "iopub.status.busy": "2025-04-11T09:06:32.147612Z",
     "iopub.status.idle": "2025-04-11T09:06:32.160504Z",
     "shell.execute_reply": "2025-04-11T09:06:32.159779Z",
     "shell.execute_reply.started": "2025-04-11T09:06:32.147787Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    return {\n",
    "        'english': batch['english'],\n",
    "        'non_english': batch['non_english'],\n",
    "        'label': teacher_model.encode(batch['english'], padding=True, truncation=True)\n",
    "   } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:06:32.161421Z",
     "iopub.status.busy": "2025-04-11T09:06:32.161208Z",
     "iopub.status.idle": "2025-04-11T09:10:29.639644Z",
     "shell.execute_reply": "2025-04-11T09:10:29.638834Z",
     "shell.execute_reply.started": "2025-04-11T09:06:32.161405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1768e4e79c6144d4ae7d3deeff89624d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/201883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b144779c254d229ebbffd35d8501b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04934479e5df403580dc6291f0daceb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2160a7a68f148539f529272e8310555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b633618d27475aa2b0aa28e48f98b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32c8244b28d4bce8982a9fcd9c69753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa200a6fba148fb94090f52025ff266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d75209d8b0b4e5e835f32299ce95708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bab7696d51488b9e3a3f9d3241d2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7382115e6a3a41c28cbd2b9f3e9cd2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/309 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_labeled = train_dataset.map(prepare_dataset, batched=True, batch_size=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:10:29.640840Z",
     "iopub.status.busy": "2025-04-11T09:10:29.640593Z",
     "iopub.status.idle": "2025-04-11T09:10:29.645974Z",
     "shell.execute_reply": "2025-04-11T09:10:29.645280Z",
     "shell.execute_reply.started": "2025-04-11T09:10:29.640813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['english', 'non_english', 'label'],\n",
       "    num_rows: 201883\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:10:29.646968Z",
     "iopub.status.busy": "2025-04-11T09:10:29.646707Z",
     "iopub.status.idle": "2025-04-11T09:10:42.822758Z",
     "shell.execute_reply": "2025-04-11T09:10:42.822014Z",
     "shell.execute_reply.started": "2025-04-11T09:10:29.646946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609e30094ec24a17a7d401a3273aa67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/993 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b180c4283c584b92932cb9cb12fded41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = eval_dataset.map(prepare_dataset, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:10:42.823838Z",
     "iopub.status.busy": "2025-04-11T09:10:42.823630Z",
     "iopub.status.idle": "2025-04-11T09:10:42.828354Z",
     "shell.execute_reply": "2025-04-11T09:10:42.827697Z",
     "shell.execute_reply.started": "2025-04-11T09:10:42.823820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['english', 'non_english', 'label'],\n",
       "    num_rows: 993\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining loss function and evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:10:42.829193Z",
     "iopub.status.busy": "2025-04-11T09:10:42.828927Z",
     "iopub.status.idle": "2025-04-11T09:10:42.846488Z",
     "shell.execute_reply": "2025-04-11T09:10:42.845900Z",
     "shell.execute_reply.started": "2025-04-11T09:10:42.829133Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers.losses import MSELoss\n",
    "\n",
    "# Computes loss between computed sentence embeddings by student ('english' and 'non_english') and target computed by teacher ('label') \n",
    "mse_loss = MSELoss(model=student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:10:42.847380Z",
     "iopub.status.busy": "2025-04-11T09:10:42.847206Z",
     "iopub.status.idle": "2025-04-11T09:10:46.584332Z",
     "shell.execute_reply": "2025-04-11T09:10:46.583618Z",
     "shell.execute_reply.started": "2025-04-11T09:10:42.847367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fe3814622244d6942c280a8d513d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4549bb263509444988f3531e4bfefd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "en-en.jsonl.gz:   0%|          | 0.00/8.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03578ff7a9b948bcbb21bc84bf9d0091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602f1e6a6e3d467ea7003627d3b5c914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cf6477651646c8b97f7285db4145ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import MSEEvaluator, EmbeddingSimilarityEvaluator, SequentialEvaluator \n",
    "\n",
    "\n",
    "# From documentation: The MSE is computed between ||teacher.encode(source_sentences) - student.encode(target_sentences)||.\n",
    "mse_eval = MSEEvaluator(\n",
    "    source_sentences=eval_dataset['english'],\n",
    "    target_sentences=eval_dataset['non_english'],\n",
    "    name='mse-en-ua',\n",
    "    teacher_model=teacher_model,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# STS Benchmark (Semantic Textual Similarity Benchmark)\n",
    "en_en_dataset = load_dataset('mteb/sts17-crosslingual-sts', 'en-en', split='test')\n",
    "en_ua_dataset = load_dataset('csv', data_files='/kaggle/input/sts-17-ua/sts17-en-ua-gpt-4o.csv', split='train') # when loading from csv by default train split is assigned\n",
    "ua_ua_dataset = load_dataset('csv', data_files='/kaggle/input/sts-17-ua/sts17-ua-ua-gpt-4o.csv', split='train')  # when loading from csv by default train split is assigned\n",
    "\n",
    "# From documentation: Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation in comparison to the gold standard labels. \n",
    "en_en_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_en_dataset['sentence1'],\n",
    "    sentences2=en_en_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_en_dataset['score']],  # normalizing to score from to 1\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-en',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "en_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_ua_dataset['sentence1'],\n",
    "    sentences2=en_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "ua_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=ua_ua_dataset['sentence1'],\n",
    "    sentences2=ua_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in ua_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-ua-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Composing evaluators in one chain! \n",
    "evaluator = SequentialEvaluator([mse_eval, en_en_eval, en_ua_eval, ua_ua_eval]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:10:46.585507Z",
     "iopub.status.busy": "2025-04-11T09:10:46.585300Z",
     "iopub.status.idle": "2025-04-11T09:10:46.617152Z",
     "shell.execute_reply": "2025-04-11T09:10:46.616543Z",
     "shell.execute_reply.started": "2025-04-11T09:10:46.585490Z"
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "\n",
    "train_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir='./xlm-roberta-ua-distilled',\n",
    "    fp16=False,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=3,  # simulate batch of accum_steps * per_device_train_batch_size = 3 * 16 = 48\n",
    "    \n",
    "    eval_steps=256, \n",
    "    eval_strategy='steps',\n",
    "    \n",
    "    save_steps=256, \n",
    "    save_strategy='steps',\n",
    "    save_total_limit=2,\n",
    "    \n",
    "    logging_steps=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:10:46.618088Z",
     "iopub.status.busy": "2025-04-11T09:10:46.617879Z",
     "iopub.status.idle": "2025-04-11T09:10:49.434580Z",
     "shell.execute_reply": "2025-04-11T09:10:49.433794Z",
     "shell.execute_reply.started": "2025-04-11T09:10:46.618072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=student_model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataset_labeled,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=mse_loss,\n",
    "    evaluator=evaluator \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T09:10:49.435636Z",
     "iopub.status.busy": "2025-04-11T09:10:49.435347Z",
     "iopub.status.idle": "2025-04-11T13:45:16.326349Z",
     "shell.execute_reply": "2025-04-11T13:45:16.325755Z",
     "shell.execute_reply.started": "2025-04-11T09:10:49.435606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21030' max='21030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21030/21030 4:34:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse-en-ua Negative Mse</th>\n",
       "      <th>Sts17-en-en Pearson Cosine</th>\n",
       "      <th>Sts17-en-en Spearman Cosine</th>\n",
       "      <th>Sts17-en-ua Pearson Cosine</th>\n",
       "      <th>Sts17-en-ua Spearman Cosine</th>\n",
       "      <th>Sts17-ua-ua Pearson Cosine</th>\n",
       "      <th>Sts17-ua-ua Spearman Cosine</th>\n",
       "      <th>Sequential Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.083567</td>\n",
       "      <td>-9.047288</td>\n",
       "      <td>0.059548</td>\n",
       "      <td>0.173122</td>\n",
       "      <td>-0.033824</td>\n",
       "      <td>-0.048771</td>\n",
       "      <td>0.019021</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>0.028516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.270461</td>\n",
       "      <td>-29.518756</td>\n",
       "      <td>-0.043769</td>\n",
       "      <td>0.057961</td>\n",
       "      <td>0.099155</td>\n",
       "      <td>-0.067967</td>\n",
       "      <td>0.128295</td>\n",
       "      <td>0.274267</td>\n",
       "      <td>0.274267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.110842</td>\n",
       "      <td>-18.071407</td>\n",
       "      <td>0.175364</td>\n",
       "      <td>0.191009</td>\n",
       "      <td>-0.008102</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.056728</td>\n",
       "      <td>0.176098</td>\n",
       "      <td>0.176098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>-20.275068</td>\n",
       "      <td>-0.038271</td>\n",
       "      <td>0.060960</td>\n",
       "      <td>0.100826</td>\n",
       "      <td>0.095551</td>\n",
       "      <td>0.217610</td>\n",
       "      <td>0.231156</td>\n",
       "      <td>0.231156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>0.321619</td>\n",
       "      <td>-31.981030</td>\n",
       "      <td>0.150335</td>\n",
       "      <td>0.175102</td>\n",
       "      <td>0.167003</td>\n",
       "      <td>0.151609</td>\n",
       "      <td>0.183439</td>\n",
       "      <td>0.254498</td>\n",
       "      <td>0.254498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1536</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>-20.458837</td>\n",
       "      <td>0.205979</td>\n",
       "      <td>0.198364</td>\n",
       "      <td>-0.073896</td>\n",
       "      <td>-0.102256</td>\n",
       "      <td>0.109237</td>\n",
       "      <td>0.178505</td>\n",
       "      <td>0.178505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.280708</td>\n",
       "      <td>-28.385133</td>\n",
       "      <td>0.076089</td>\n",
       "      <td>0.176890</td>\n",
       "      <td>-0.049274</td>\n",
       "      <td>-0.158114</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.177335</td>\n",
       "      <td>0.177335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2048</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.135312</td>\n",
       "      <td>-19.327693</td>\n",
       "      <td>0.272888</td>\n",
       "      <td>0.328820</td>\n",
       "      <td>-0.086076</td>\n",
       "      <td>-0.107651</td>\n",
       "      <td>0.042067</td>\n",
       "      <td>0.141469</td>\n",
       "      <td>0.141469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2304</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>0.113981</td>\n",
       "      <td>-18.240812</td>\n",
       "      <td>0.346075</td>\n",
       "      <td>0.367256</td>\n",
       "      <td>0.086045</td>\n",
       "      <td>0.078545</td>\n",
       "      <td>0.045792</td>\n",
       "      <td>0.208089</td>\n",
       "      <td>0.208089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.096401</td>\n",
       "      <td>-15.752825</td>\n",
       "      <td>0.185638</td>\n",
       "      <td>0.255947</td>\n",
       "      <td>0.217652</td>\n",
       "      <td>0.230752</td>\n",
       "      <td>0.203433</td>\n",
       "      <td>0.174880</td>\n",
       "      <td>0.174880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2816</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.098839</td>\n",
       "      <td>-15.193728</td>\n",
       "      <td>0.189045</td>\n",
       "      <td>0.252690</td>\n",
       "      <td>0.187719</td>\n",
       "      <td>0.200351</td>\n",
       "      <td>0.194908</td>\n",
       "      <td>0.184962</td>\n",
       "      <td>0.184962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3072</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.098398</td>\n",
       "      <td>-16.212876</td>\n",
       "      <td>0.250286</td>\n",
       "      <td>0.307481</td>\n",
       "      <td>0.135829</td>\n",
       "      <td>0.116177</td>\n",
       "      <td>0.133345</td>\n",
       "      <td>0.244539</td>\n",
       "      <td>0.244539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3328</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.097052</td>\n",
       "      <td>-13.750845</td>\n",
       "      <td>0.214768</td>\n",
       "      <td>0.295702</td>\n",
       "      <td>0.099980</td>\n",
       "      <td>0.102314</td>\n",
       "      <td>0.140617</td>\n",
       "      <td>0.239408</td>\n",
       "      <td>0.239408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3584</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>0.135534</td>\n",
       "      <td>-20.585239</td>\n",
       "      <td>0.191030</td>\n",
       "      <td>0.230958</td>\n",
       "      <td>-0.013819</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.200083</td>\n",
       "      <td>0.215809</td>\n",
       "      <td>0.215809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.152574</td>\n",
       "      <td>-22.876884</td>\n",
       "      <td>0.158581</td>\n",
       "      <td>0.194561</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>0.061692</td>\n",
       "      <td>0.108032</td>\n",
       "      <td>0.213908</td>\n",
       "      <td>0.213908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4096</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.096662</td>\n",
       "      <td>-11.890332</td>\n",
       "      <td>0.236707</td>\n",
       "      <td>0.274277</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.051709</td>\n",
       "      <td>0.155068</td>\n",
       "      <td>0.216381</td>\n",
       "      <td>0.216381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4352</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>0.169165</td>\n",
       "      <td>-20.189714</td>\n",
       "      <td>0.189001</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.210121</td>\n",
       "      <td>0.250605</td>\n",
       "      <td>0.245799</td>\n",
       "      <td>0.224950</td>\n",
       "      <td>0.224950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4608</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.109518</td>\n",
       "      <td>-11.287777</td>\n",
       "      <td>0.183907</td>\n",
       "      <td>0.292138</td>\n",
       "      <td>0.059231</td>\n",
       "      <td>0.050126</td>\n",
       "      <td>0.207869</td>\n",
       "      <td>0.215106</td>\n",
       "      <td>0.215106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4864</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.097806</td>\n",
       "      <td>-11.273549</td>\n",
       "      <td>0.198225</td>\n",
       "      <td>0.270425</td>\n",
       "      <td>0.136598</td>\n",
       "      <td>0.193940</td>\n",
       "      <td>0.138254</td>\n",
       "      <td>0.274735</td>\n",
       "      <td>0.274735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5120</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>-11.625037</td>\n",
       "      <td>0.247303</td>\n",
       "      <td>0.286294</td>\n",
       "      <td>0.118659</td>\n",
       "      <td>0.112116</td>\n",
       "      <td>0.256318</td>\n",
       "      <td>0.285451</td>\n",
       "      <td>0.285451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5376</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.098455</td>\n",
       "      <td>-9.832387</td>\n",
       "      <td>0.150458</td>\n",
       "      <td>0.223222</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>0.071621</td>\n",
       "      <td>0.269210</td>\n",
       "      <td>0.313020</td>\n",
       "      <td>0.313020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5632</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>-9.070963</td>\n",
       "      <td>0.213946</td>\n",
       "      <td>0.238732</td>\n",
       "      <td>0.110936</td>\n",
       "      <td>0.075279</td>\n",
       "      <td>0.285725</td>\n",
       "      <td>0.306921</td>\n",
       "      <td>0.306921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5888</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.091511</td>\n",
       "      <td>-9.127740</td>\n",
       "      <td>0.127945</td>\n",
       "      <td>0.198600</td>\n",
       "      <td>0.072763</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>0.225957</td>\n",
       "      <td>0.306876</td>\n",
       "      <td>0.306876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6144</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.082315</td>\n",
       "      <td>-8.361360</td>\n",
       "      <td>0.065090</td>\n",
       "      <td>0.197875</td>\n",
       "      <td>-0.035248</td>\n",
       "      <td>-0.038785</td>\n",
       "      <td>0.140976</td>\n",
       "      <td>0.224473</td>\n",
       "      <td>0.224473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.140568</td>\n",
       "      <td>-16.924830</td>\n",
       "      <td>0.145419</td>\n",
       "      <td>0.203279</td>\n",
       "      <td>-0.005138</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.227311</td>\n",
       "      <td>0.227311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6656</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.067646</td>\n",
       "      <td>-6.720369</td>\n",
       "      <td>0.177372</td>\n",
       "      <td>0.200980</td>\n",
       "      <td>-0.081703</td>\n",
       "      <td>-0.068976</td>\n",
       "      <td>0.226122</td>\n",
       "      <td>0.262086</td>\n",
       "      <td>0.262086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6912</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.065577</td>\n",
       "      <td>-6.283326</td>\n",
       "      <td>0.215978</td>\n",
       "      <td>0.237694</td>\n",
       "      <td>-0.020678</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.206933</td>\n",
       "      <td>0.244977</td>\n",
       "      <td>0.244977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7168</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.040634</td>\n",
       "      <td>-4.318890</td>\n",
       "      <td>0.162498</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>-0.070656</td>\n",
       "      <td>-0.037680</td>\n",
       "      <td>0.187344</td>\n",
       "      <td>0.302618</td>\n",
       "      <td>0.302618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7424</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>-3.830314</td>\n",
       "      <td>0.204292</td>\n",
       "      <td>0.241508</td>\n",
       "      <td>-0.075059</td>\n",
       "      <td>-0.073486</td>\n",
       "      <td>0.286132</td>\n",
       "      <td>0.323134</td>\n",
       "      <td>0.323134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7680</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.034513</td>\n",
       "      <td>-3.716299</td>\n",
       "      <td>0.111473</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.017332</td>\n",
       "      <td>0.035020</td>\n",
       "      <td>0.278430</td>\n",
       "      <td>0.349986</td>\n",
       "      <td>0.349986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7936</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.046633</td>\n",
       "      <td>-5.178900</td>\n",
       "      <td>0.233039</td>\n",
       "      <td>0.286756</td>\n",
       "      <td>-0.033108</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.188368</td>\n",
       "      <td>0.265709</td>\n",
       "      <td>0.265709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8192</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.040638</td>\n",
       "      <td>-4.353386</td>\n",
       "      <td>0.265664</td>\n",
       "      <td>0.294391</td>\n",
       "      <td>-0.007017</td>\n",
       "      <td>-0.010440</td>\n",
       "      <td>0.228033</td>\n",
       "      <td>0.281326</td>\n",
       "      <td>0.281326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8448</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.035227</td>\n",
       "      <td>-3.726076</td>\n",
       "      <td>0.224684</td>\n",
       "      <td>0.256251</td>\n",
       "      <td>-0.026477</td>\n",
       "      <td>-0.032773</td>\n",
       "      <td>0.233258</td>\n",
       "      <td>0.266999</td>\n",
       "      <td>0.266999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8704</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>-3.324902</td>\n",
       "      <td>0.192197</td>\n",
       "      <td>0.248229</td>\n",
       "      <td>-0.039334</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.221858</td>\n",
       "      <td>0.303194</td>\n",
       "      <td>0.303194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8960</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.034915</td>\n",
       "      <td>-3.556659</td>\n",
       "      <td>0.165059</td>\n",
       "      <td>0.209050</td>\n",
       "      <td>-0.014641</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.178795</td>\n",
       "      <td>0.213778</td>\n",
       "      <td>0.213778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9216</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.040801</td>\n",
       "      <td>-4.056235</td>\n",
       "      <td>0.181516</td>\n",
       "      <td>0.209244</td>\n",
       "      <td>-0.007006</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.190298</td>\n",
       "      <td>0.221403</td>\n",
       "      <td>0.221403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9472</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>-3.762329</td>\n",
       "      <td>0.122107</td>\n",
       "      <td>0.201993</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>0.161732</td>\n",
       "      <td>0.236061</td>\n",
       "      <td>0.236061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9728</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.033251</td>\n",
       "      <td>-3.455455</td>\n",
       "      <td>0.112303</td>\n",
       "      <td>0.182536</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.044592</td>\n",
       "      <td>0.158347</td>\n",
       "      <td>0.259876</td>\n",
       "      <td>0.259876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9984</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>-3.481307</td>\n",
       "      <td>0.171998</td>\n",
       "      <td>0.251975</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.197315</td>\n",
       "      <td>0.284410</td>\n",
       "      <td>0.284410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10240</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.037960</td>\n",
       "      <td>-3.982322</td>\n",
       "      <td>0.202698</td>\n",
       "      <td>0.306351</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.193807</td>\n",
       "      <td>0.292723</td>\n",
       "      <td>0.292723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10496</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>-4.084916</td>\n",
       "      <td>0.217023</td>\n",
       "      <td>0.324628</td>\n",
       "      <td>0.038135</td>\n",
       "      <td>0.029969</td>\n",
       "      <td>0.238507</td>\n",
       "      <td>0.321768</td>\n",
       "      <td>0.321768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10752</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.037961</td>\n",
       "      <td>-3.973303</td>\n",
       "      <td>0.223618</td>\n",
       "      <td>0.362333</td>\n",
       "      <td>0.050205</td>\n",
       "      <td>0.078355</td>\n",
       "      <td>0.270020</td>\n",
       "      <td>0.356891</td>\n",
       "      <td>0.356891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11008</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.034241</td>\n",
       "      <td>-3.430824</td>\n",
       "      <td>0.247850</td>\n",
       "      <td>0.370112</td>\n",
       "      <td>0.051415</td>\n",
       "      <td>0.070176</td>\n",
       "      <td>0.257625</td>\n",
       "      <td>0.371702</td>\n",
       "      <td>0.371702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11264</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>-3.445379</td>\n",
       "      <td>0.263882</td>\n",
       "      <td>0.358797</td>\n",
       "      <td>0.069668</td>\n",
       "      <td>0.079403</td>\n",
       "      <td>0.290012</td>\n",
       "      <td>0.354114</td>\n",
       "      <td>0.354114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11520</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.036732</td>\n",
       "      <td>-3.746938</td>\n",
       "      <td>0.313815</td>\n",
       "      <td>0.425132</td>\n",
       "      <td>0.129081</td>\n",
       "      <td>0.098701</td>\n",
       "      <td>0.299924</td>\n",
       "      <td>0.361456</td>\n",
       "      <td>0.361456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11776</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>-3.477765</td>\n",
       "      <td>0.253984</td>\n",
       "      <td>0.338525</td>\n",
       "      <td>0.101779</td>\n",
       "      <td>0.082748</td>\n",
       "      <td>0.277022</td>\n",
       "      <td>0.356177</td>\n",
       "      <td>0.356177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12032</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.029432</td>\n",
       "      <td>-2.968309</td>\n",
       "      <td>0.309682</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.096206</td>\n",
       "      <td>0.070818</td>\n",
       "      <td>0.323113</td>\n",
       "      <td>0.392350</td>\n",
       "      <td>0.392350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12288</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.029369</td>\n",
       "      <td>-2.976132</td>\n",
       "      <td>0.322616</td>\n",
       "      <td>0.440770</td>\n",
       "      <td>0.168211</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.319535</td>\n",
       "      <td>0.395695</td>\n",
       "      <td>0.395695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12544</td>\n",
       "      <td>0.073200</td>\n",
       "      <td>0.028832</td>\n",
       "      <td>-2.875748</td>\n",
       "      <td>0.356899</td>\n",
       "      <td>0.447328</td>\n",
       "      <td>0.162905</td>\n",
       "      <td>0.152735</td>\n",
       "      <td>0.342884</td>\n",
       "      <td>0.399234</td>\n",
       "      <td>0.399234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.027892</td>\n",
       "      <td>-2.792687</td>\n",
       "      <td>0.361380</td>\n",
       "      <td>0.448347</td>\n",
       "      <td>0.162783</td>\n",
       "      <td>0.153278</td>\n",
       "      <td>0.319218</td>\n",
       "      <td>0.374043</td>\n",
       "      <td>0.374043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13056</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.027604</td>\n",
       "      <td>-2.780667</td>\n",
       "      <td>0.372464</td>\n",
       "      <td>0.464321</td>\n",
       "      <td>0.144559</td>\n",
       "      <td>0.141230</td>\n",
       "      <td>0.304485</td>\n",
       "      <td>0.363019</td>\n",
       "      <td>0.363019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13312</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.026346</td>\n",
       "      <td>-2.678585</td>\n",
       "      <td>0.374372</td>\n",
       "      <td>0.459202</td>\n",
       "      <td>0.155889</td>\n",
       "      <td>0.138402</td>\n",
       "      <td>0.321042</td>\n",
       "      <td>0.373159</td>\n",
       "      <td>0.373159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13568</td>\n",
       "      <td>0.071600</td>\n",
       "      <td>0.026693</td>\n",
       "      <td>-2.719651</td>\n",
       "      <td>0.388355</td>\n",
       "      <td>0.468730</td>\n",
       "      <td>0.144384</td>\n",
       "      <td>0.116137</td>\n",
       "      <td>0.322452</td>\n",
       "      <td>0.372196</td>\n",
       "      <td>0.372196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13824</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>-2.484887</td>\n",
       "      <td>0.356041</td>\n",
       "      <td>0.432513</td>\n",
       "      <td>0.183654</td>\n",
       "      <td>0.154034</td>\n",
       "      <td>0.350200</td>\n",
       "      <td>0.411788</td>\n",
       "      <td>0.411788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14080</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.023789</td>\n",
       "      <td>-2.447723</td>\n",
       "      <td>0.380175</td>\n",
       "      <td>0.462604</td>\n",
       "      <td>0.230338</td>\n",
       "      <td>0.195252</td>\n",
       "      <td>0.376298</td>\n",
       "      <td>0.423389</td>\n",
       "      <td>0.423389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14336</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>-2.415080</td>\n",
       "      <td>0.367801</td>\n",
       "      <td>0.437868</td>\n",
       "      <td>0.178767</td>\n",
       "      <td>0.162147</td>\n",
       "      <td>0.349807</td>\n",
       "      <td>0.410725</td>\n",
       "      <td>0.410725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14592</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.023430</td>\n",
       "      <td>-2.425351</td>\n",
       "      <td>0.386895</td>\n",
       "      <td>0.457503</td>\n",
       "      <td>0.223974</td>\n",
       "      <td>0.182295</td>\n",
       "      <td>0.365603</td>\n",
       "      <td>0.424799</td>\n",
       "      <td>0.424799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14848</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>-2.403995</td>\n",
       "      <td>0.405799</td>\n",
       "      <td>0.467778</td>\n",
       "      <td>0.254467</td>\n",
       "      <td>0.226780</td>\n",
       "      <td>0.382854</td>\n",
       "      <td>0.435470</td>\n",
       "      <td>0.435470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15104</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.022770</td>\n",
       "      <td>-2.353493</td>\n",
       "      <td>0.422762</td>\n",
       "      <td>0.479188</td>\n",
       "      <td>0.259455</td>\n",
       "      <td>0.237241</td>\n",
       "      <td>0.386513</td>\n",
       "      <td>0.433707</td>\n",
       "      <td>0.433707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15360</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>-2.346300</td>\n",
       "      <td>0.430754</td>\n",
       "      <td>0.490279</td>\n",
       "      <td>0.254097</td>\n",
       "      <td>0.231357</td>\n",
       "      <td>0.403122</td>\n",
       "      <td>0.452252</td>\n",
       "      <td>0.452252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15616</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>-2.331739</td>\n",
       "      <td>0.451383</td>\n",
       "      <td>0.493598</td>\n",
       "      <td>0.267505</td>\n",
       "      <td>0.236801</td>\n",
       "      <td>0.416764</td>\n",
       "      <td>0.457778</td>\n",
       "      <td>0.457778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15872</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.022301</td>\n",
       "      <td>-2.315603</td>\n",
       "      <td>0.463702</td>\n",
       "      <td>0.496194</td>\n",
       "      <td>0.279468</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.421687</td>\n",
       "      <td>0.470965</td>\n",
       "      <td>0.470965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16128</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.022106</td>\n",
       "      <td>-2.297725</td>\n",
       "      <td>0.464799</td>\n",
       "      <td>0.505659</td>\n",
       "      <td>0.283130</td>\n",
       "      <td>0.263255</td>\n",
       "      <td>0.424884</td>\n",
       "      <td>0.474728</td>\n",
       "      <td>0.474728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16384</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.021833</td>\n",
       "      <td>-2.270632</td>\n",
       "      <td>0.471682</td>\n",
       "      <td>0.514045</td>\n",
       "      <td>0.284807</td>\n",
       "      <td>0.269425</td>\n",
       "      <td>0.421787</td>\n",
       "      <td>0.470728</td>\n",
       "      <td>0.470728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16640</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.021675</td>\n",
       "      <td>-2.260361</td>\n",
       "      <td>0.477602</td>\n",
       "      <td>0.519468</td>\n",
       "      <td>0.276590</td>\n",
       "      <td>0.263751</td>\n",
       "      <td>0.428410</td>\n",
       "      <td>0.478753</td>\n",
       "      <td>0.478753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16896</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.021582</td>\n",
       "      <td>-2.251321</td>\n",
       "      <td>0.479677</td>\n",
       "      <td>0.522040</td>\n",
       "      <td>0.292111</td>\n",
       "      <td>0.285113</td>\n",
       "      <td>0.436033</td>\n",
       "      <td>0.493791</td>\n",
       "      <td>0.493791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17152</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.021411</td>\n",
       "      <td>-2.234609</td>\n",
       "      <td>0.474184</td>\n",
       "      <td>0.512802</td>\n",
       "      <td>0.296369</td>\n",
       "      <td>0.280923</td>\n",
       "      <td>0.440974</td>\n",
       "      <td>0.495654</td>\n",
       "      <td>0.495654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17408</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>-2.230566</td>\n",
       "      <td>0.498082</td>\n",
       "      <td>0.532562</td>\n",
       "      <td>0.311859</td>\n",
       "      <td>0.299860</td>\n",
       "      <td>0.442274</td>\n",
       "      <td>0.494787</td>\n",
       "      <td>0.494787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17664</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>-2.228825</td>\n",
       "      <td>0.492042</td>\n",
       "      <td>0.526415</td>\n",
       "      <td>0.317529</td>\n",
       "      <td>0.303090</td>\n",
       "      <td>0.448632</td>\n",
       "      <td>0.496990</td>\n",
       "      <td>0.496990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17920</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.021043</td>\n",
       "      <td>-2.205849</td>\n",
       "      <td>0.501453</td>\n",
       "      <td>0.540704</td>\n",
       "      <td>0.323847</td>\n",
       "      <td>0.315792</td>\n",
       "      <td>0.460805</td>\n",
       "      <td>0.511219</td>\n",
       "      <td>0.511219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18176</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>-2.199390</td>\n",
       "      <td>0.508121</td>\n",
       "      <td>0.550764</td>\n",
       "      <td>0.330168</td>\n",
       "      <td>0.320498</td>\n",
       "      <td>0.464325</td>\n",
       "      <td>0.512689</td>\n",
       "      <td>0.512689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18432</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.020869</td>\n",
       "      <td>-2.192426</td>\n",
       "      <td>0.507338</td>\n",
       "      <td>0.545923</td>\n",
       "      <td>0.322844</td>\n",
       "      <td>0.310644</td>\n",
       "      <td>0.468253</td>\n",
       "      <td>0.513995</td>\n",
       "      <td>0.513995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18688</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>-2.195059</td>\n",
       "      <td>0.515208</td>\n",
       "      <td>0.551500</td>\n",
       "      <td>0.342667</td>\n",
       "      <td>0.332510</td>\n",
       "      <td>0.468857</td>\n",
       "      <td>0.518887</td>\n",
       "      <td>0.518887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18944</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>-2.171100</td>\n",
       "      <td>0.524738</td>\n",
       "      <td>0.559235</td>\n",
       "      <td>0.364542</td>\n",
       "      <td>0.351563</td>\n",
       "      <td>0.483806</td>\n",
       "      <td>0.526799</td>\n",
       "      <td>0.526799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>-2.167065</td>\n",
       "      <td>0.522144</td>\n",
       "      <td>0.557149</td>\n",
       "      <td>0.356975</td>\n",
       "      <td>0.343272</td>\n",
       "      <td>0.479484</td>\n",
       "      <td>0.524693</td>\n",
       "      <td>0.524693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19456</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>0.020588</td>\n",
       "      <td>-2.168317</td>\n",
       "      <td>0.527284</td>\n",
       "      <td>0.560284</td>\n",
       "      <td>0.367513</td>\n",
       "      <td>0.349352</td>\n",
       "      <td>0.481191</td>\n",
       "      <td>0.528327</td>\n",
       "      <td>0.528327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19712</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.020505</td>\n",
       "      <td>-2.160733</td>\n",
       "      <td>0.522394</td>\n",
       "      <td>0.560854</td>\n",
       "      <td>0.367966</td>\n",
       "      <td>0.352753</td>\n",
       "      <td>0.481319</td>\n",
       "      <td>0.530414</td>\n",
       "      <td>0.530414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19968</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.020520</td>\n",
       "      <td>-2.162903</td>\n",
       "      <td>0.529341</td>\n",
       "      <td>0.564760</td>\n",
       "      <td>0.372195</td>\n",
       "      <td>0.358564</td>\n",
       "      <td>0.482618</td>\n",
       "      <td>0.527885</td>\n",
       "      <td>0.527885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20224</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>-2.157187</td>\n",
       "      <td>0.527538</td>\n",
       "      <td>0.561683</td>\n",
       "      <td>0.371140</td>\n",
       "      <td>0.359758</td>\n",
       "      <td>0.480272</td>\n",
       "      <td>0.526066</td>\n",
       "      <td>0.526066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20480</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>-2.157035</td>\n",
       "      <td>0.525453</td>\n",
       "      <td>0.561392</td>\n",
       "      <td>0.367021</td>\n",
       "      <td>0.353744</td>\n",
       "      <td>0.482639</td>\n",
       "      <td>0.526164</td>\n",
       "      <td>0.526164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20736</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>-2.152674</td>\n",
       "      <td>0.525161</td>\n",
       "      <td>0.558344</td>\n",
       "      <td>0.365172</td>\n",
       "      <td>0.351678</td>\n",
       "      <td>0.480357</td>\n",
       "      <td>0.526164</td>\n",
       "      <td>0.526164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20992</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.020401</td>\n",
       "      <td>-2.152108</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.563160</td>\n",
       "      <td>0.368378</td>\n",
       "      <td>0.354885</td>\n",
       "      <td>0.483212</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.527187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21030, training_loss=0.07928810872410345, metrics={'train_runtime': 16466.3615, 'train_samples_per_second': 61.302, 'train_steps_per_second': 1.277, 'total_flos': 0.0, 'train_loss': 0.07928810872410345, 'epoch': 5.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:45:16.327369Z",
     "iopub.status.busy": "2025-04-11T13:45:16.327063Z",
     "iopub.status.idle": "2025-04-11T13:45:23.743895Z",
     "shell.execute_reply": "2025-04-11T13:45:23.743177Z",
     "shell.execute_reply.started": "2025-04-11T13:45:16.327352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.02040005289018154,\n",
       " 'eval_mse-en-ua_negative_mse': -2.1519742906093597,\n",
       " 'eval_sts17-en-en_pearson_cosine': 0.5273567306654277,\n",
       " 'eval_sts17-en-en_spearman_cosine': 0.5630721403406446,\n",
       " 'eval_sts17-en-ua_pearson_cosine': 0.36821999547054507,\n",
       " 'eval_sts17-en-ua_spearman_cosine': 0.3551228317268819,\n",
       " 'eval_sts17-ua-ua_pearson_cosine': 0.48312967918474736,\n",
       " 'eval_sts17-ua-ua_spearman_cosine': 0.5271830395192819,\n",
       " 'eval_sequential_score': 0.5271830395192819,\n",
       " 'eval_runtime': 7.4068,\n",
       " 'eval_samples_per_second': 134.065,\n",
       " 'eval_steps_per_second': 8.506,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:45:23.747509Z",
     "iopub.status.busy": "2025-04-11T13:45:23.747302Z",
     "iopub.status.idle": "2025-04-11T13:45:26.942661Z",
     "shell.execute_reply": "2025-04-11T13:45:26.941890Z",
     "shell.execute_reply.started": "2025-04-11T13:45:23.747492Z"
    }
   },
   "outputs": [],
   "source": [
    "student_model.save('./xlm-roberta-ua-distilled/final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:53:52.206252Z",
     "iopub.status.busy": "2025-04-11T13:53:52.205496Z",
     "iopub.status.idle": "2025-04-11T13:54:27.937341Z",
     "shell.execute_reply": "2025-04-11T13:54:27.936476Z",
     "shell.execute_reply.started": "2025-04-11T13:53:52.206224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0bac18235f4ed2b9848a27cbf8e125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf32671cd6eb468bba3d86304717af70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5ed5e2aa6f4242897c262382b628d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc269a203bc7429ca9150e353032bb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/panalexeu/xlm-roberta-ua-distilled/commit/495c39c51e6ebbd40c242d77629b8b57a70caab3'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "os.environ['HF_TOKEN'] = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "student_model.push_to_hub('xlm-roberta-ua-distilled')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7107498,
     "sourceId": 11356899,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
