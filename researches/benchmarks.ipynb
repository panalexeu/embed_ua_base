{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525e7ec4-a479-48ce-80c6-58422aa2444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q mteb\n",
    "!uv pip install -q sentence-transformers\n",
    "!uv pip install -q pandas\n",
    "!uv pip install -q rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720cff8d-3fb2-4579-a769-c4baf093a660",
   "metadata": {},
   "source": [
    "### Post-train Research\n",
    "\n",
    "In this notebook, some inference tests and benchmarking of the fine-tuned and original models are performed. \n",
    "\n",
    "One of the benchmarks is STS-17 in the following configurations: en-en, en-ua (machine translated), ua-ua (machine translated). \n",
    "\n",
    "The machine translation of the STS-17 benchmark to the Ukrainian language was performed in this [notebook](../dataset_translation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2dd1c9-bb66-4d12-afbf-0f527fcca7aa",
   "metadata": {},
   "source": [
    "#### Loading the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb03e91-d904-4ed5-8c24-f31b2c95b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name FacebookAI/xlm-roberta-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "# original \n",
    "xlm_roberta = SentenceTransformer('FacebookAI/xlm-roberta-base')\n",
    "xlm_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92453756-b328-47bc-9014-1e10a6af9d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tuned \n",
    "xlm_roberta_ua_distilled = SentenceTransformer('panalexeu/xlm-roberta-ua-distilled')\n",
    "xlm_roberta_ua_distilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09c6cf02-cdce-43ae-acc9-61c700ba7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assure that the models have identical configurations \n",
    "assert xlm_roberta[0].get_config_dict() == xlm_roberta_ua_distilled[0].get_config_dict()\n",
    "assert xlm_roberta[1].get_config_dict() == xlm_roberta_ua_distilled[1].get_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4467d423-d56e-4bd3-aabb-d9cf3991ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# teacher model\n",
    "multi_qa_mpnet = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-dot-v1')\n",
    "multi_qa_mpnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8502c9-c755-4e5b-bd96-6d679f7695de",
   "metadata": {},
   "source": [
    "#### STS-17 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761730af-db2b-4e3f-be6f-553e985542fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since mteb/sts17-crosslingual-sts couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'en-en' at /home/oleksii/.cache/huggingface/datasets/mteb___sts17-crosslingual-sts/en-en/0.0.0/faeb762787bd10488a50c8b5be4a3b82e411949c (last modified on Wed Apr  9 19:03:01 2025).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SequentialEvaluator \n",
    "\n",
    "# STS Benchmark (Semantic Textual Similarity Benchmark)\n",
    "en_en_dataset = load_dataset('mteb/sts17-crosslingual-sts', 'en-en', split='test')\n",
    "en_ua_dataset = load_dataset('csv', data_files='../datasets/sts17-en-ua-gpt-4o.csv', split='train') # when loading from csv by default train split is assigned\n",
    "ua_ua_dataset = load_dataset('csv', data_files='../datasets/sts17-ua-ua-gpt-4o.csv', split='train')  # when loading from csv by default train split is assigned\n",
    "\n",
    "# From documentation: Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation in comparison to the gold standard labels. \n",
    "en_en_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_en_dataset['sentence1'],\n",
    "    sentences2=en_en_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_en_dataset['score']],  # normalizing to score from to 1\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-en',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "en_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_ua_dataset['sentence1'],\n",
    "    sentences2=en_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "ua_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=ua_ua_dataset['sentence1'],\n",
    "    sentences2=ua_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in ua_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-ua-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Composing evaluators in one chain! \n",
    "evaluator = SequentialEvaluator([en_en_eval, en_ua_eval, ua_ua_eval]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206a3a6-e662-4715-9afe-189efc3bd092",
   "metadata": {},
   "source": [
    "**Original** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8121c4c4-d1a7-4a9f-8f0a-df157093037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model_preparation_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0027</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.36110322291820246</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5217129934278466</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.12805525703810633</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.13454840278964744</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.302438933599461</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4151725913805182</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sequential_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4151725913805182</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.069</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'eval_model_preparation_time'\u001b[0m: \u001b[1;36m0.0027\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_pearson_cosine'\u001b[0m: \u001b[1;36m0.36110322291820246\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_spearman_cosine'\u001b[0m: \u001b[1;36m0.5217129934278466\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.12805525703810633\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.13454840278964744\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.302438933599461\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.4151725913805182\u001b[0m,\n",
       "    \u001b[32m'eval_sequential_score'\u001b[0m: \u001b[1;36m0.4151725913805182\u001b[0m,\n",
       "    \u001b[32m'eval_runtime'\u001b[0m: \u001b[1;36m2.069\u001b[0m,\n",
       "    \u001b[32m'eval_samples_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'eval_steps_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print \n",
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "res = SentenceTransformerTrainer(\n",
    "    model=xlm_roberta,\n",
    "    evaluator=evaluator\n",
    ").evaluate()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb427c7-b582-49e8-8e8e-9a25d768bc77",
   "metadata": {},
   "source": [
    "**Fine-tuned** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99fdbe8-9090-4127-9b78-e20e435bbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model_preparation_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.002</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6784819681712645</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7308493185913256</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5925553586829718</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6197606373137193</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6158998600027094</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6445750755380512</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sequential_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6445750755380512</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.7871</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'eval_model_preparation_time'\u001b[0m: \u001b[1;36m0.002\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_pearson_cosine'\u001b[0m: \u001b[1;36m0.6784819681712645\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_spearman_cosine'\u001b[0m: \u001b[1;36m0.7308493185913256\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.5925553586829718\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.6197606373137193\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.6158998600027094\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.6445750755380512\u001b[0m,\n",
       "    \u001b[32m'eval_sequential_score'\u001b[0m: \u001b[1;36m0.6445750755380512\u001b[0m,\n",
       "    \u001b[32m'eval_runtime'\u001b[0m: \u001b[1;36m1.7871\u001b[0m,\n",
       "    \u001b[32m'eval_samples_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'eval_steps_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "res = SentenceTransformerTrainer(\n",
    "    model=xlm_roberta_ua_distilled,\n",
    "    evaluator=evaluator\n",
    ").evaluate()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294309f7-15bb-4b76-b138-33a4abe1e8d9",
   "metadata": {},
   "source": [
    "**multi-qa-mpnet-base-dot-v1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c874ed1-5005-4209-8eac-b6bb2206b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_model_preparation_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0028</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7372436032190661</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-en_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7582948479414522</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17201717053290624</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-en-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1290184740058981</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_pearson_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5915510256143389</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sts17-ua-ua_spearman_cosine'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6231217598535435</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_sequential_score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6231217598535435</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_runtime'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.678</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_samples_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_steps_per_second'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'eval_model_preparation_time'\u001b[0m: \u001b[1;36m0.0028\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_pearson_cosine'\u001b[0m: \u001b[1;36m0.7372436032190661\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-en_spearman_cosine'\u001b[0m: \u001b[1;36m0.7582948479414522\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.17201717053290624\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-en-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.1290184740058981\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_pearson_cosine'\u001b[0m: \u001b[1;36m0.5915510256143389\u001b[0m,\n",
       "    \u001b[32m'eval_sts17-ua-ua_spearman_cosine'\u001b[0m: \u001b[1;36m0.6231217598535435\u001b[0m,\n",
       "    \u001b[32m'eval_sequential_score'\u001b[0m: \u001b[1;36m0.6231217598535435\u001b[0m,\n",
       "    \u001b[32m'eval_runtime'\u001b[0m: \u001b[1;36m2.678\u001b[0m,\n",
       "    \u001b[32m'eval_samples_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m,\n",
       "    \u001b[32m'eval_steps_per_second'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "res = SentenceTransformerTrainer(\n",
    "    model=multi_qa_mpnet,\n",
    "    evaluator=evaluator\n",
    ").evaluate()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caf5460-2c04-47f8-8dbc-0a613b70e11d",
   "metadata": {},
   "source": [
    "Spearman scores table: \n",
    "\n",
    "| model                                | en-en | en-ua    | ua-ua    | \n",
    "| ------------------------------------ | ----- | -------- | -------- |  \n",
    "| multi-qa-mpnet-base-dot-v1           | 75.8  | 12.9     | 62.3     |\n",
    "| XLM-RoBERTa                          | 52.2  | 13.5     | 41.5     |\n",
    "| xlm-roberta-ua-distilled*            | 73.1  | **62.0** | **64.5** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf37e42-15ef-42b4-9d97-ec7bf1bb631d",
   "metadata": {},
   "source": [
    "#### MTEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f6a12-feeb-4877-b508-255c33ebf991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mteb\n",
    "tasks = mteb.get_tasks(tasks=['WebFAQRetrieval'], languages=['ukr'])  # mteb.get_tasks(task_types=['Retrieval'], languages=['ukr'])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f451e4c-6480-437a-81c1-1af0742eea24",
   "metadata": {},
   "source": [
    "**Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f427b5e-dbe8-4493-844b-25bb277743be",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.run(xlm_roberta, encode_kwargs={\"batch_size\": 32})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4592ce0-048b-4238-9b3c-7ef132b1f5f7",
   "metadata": {},
   "source": [
    "**Fine-tuned** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a82a86-fef1-4a78-afa2-283e16fcce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.run(xlm_roberta_ua_distilled, encode_kwargs={\"batch_size\": 32})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca63b9c-0212-4d11-b7fd-afd427a8ebb4",
   "metadata": {},
   "source": [
    "**all-MiniLM-L6-v2** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a5384-8b41-4ae3-91cc-00c15ef5e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.run(multi_qa_mpnet, encode_kwargs={\"batch_size\": 32})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4afff-9996-44ea-9435-40b04916beb8",
   "metadata": {},
   "source": [
    "#### Minimal test on quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce7ada-bf00-4fed-99d3-e55b9db9eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    \"An idiot admires complexity, a genius admires simplicity.\",          # English\n",
    "    \"Ідіот захоплюється складністю, геній — простотою.\",                  # Ukrainian\n",
    "]\n",
    "\n",
    "quotes_antonyms = [\n",
    "    \"Hello, World!\",\n",
    "    \"Прощавай, Місяць.\"\n",
    "]\n",
    "\n",
    "# to check zero-shot crosslingual transfer effect \n",
    "quotes_extended = quotes + [\n",
    "    \"Идиот восхищается сложностью, гений — простотой.\",                   # Russian\n",
    "    \"Ідыёт захапляецца складанасцю, геній — прастатой.\",                  # Belarusian\n",
    "    \"Идиот се възхищава на сложността, гений — на простотата.\"            # Bulgarian\n",
    "]\n",
    "# P.S. I love Terry Davis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a4b48-90aa-459c-945b-bf2801c32b12",
   "metadata": {},
   "source": [
    "**Close quotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e16f14-964d-4ca8-8a15-c25ecd648ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = xlm_roberta.encode(quotes)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64b4f5-6959-4dba-a090-368ecf75f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7b445-5c78-455a-affe-9447a6ce7dc8",
   "metadata": {},
   "source": [
    "**Antonyms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f406ee-1022-4762-bd0c-2f0377d2691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = xlm_roberta.encode(quotes_antonyms)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320aeadb-fba2-4567-b336-41559dfbebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes_antonyms)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9e7fb-debd-496b-9640-43351acc6d89",
   "metadata": {},
   "source": [
    "**Zero-shot cross-lingual transfer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd7577-ff74-431a-a28d-57fbbeccf675",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = xlm_roberta.encode(quotes_extended)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54608e64-d595-4c4a-a66e-56460a90f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes_extended)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_ua_base",
   "language": "python",
   "name": "embed_ua_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
