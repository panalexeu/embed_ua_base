{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73c7fb7-1d6f-40d2-9aa4-aa61e5c63e5b",
   "metadata": {},
   "source": [
    "### Post train research\n",
    "\n",
    "Let's compare the intermediate results of the fine-tuned and distilled version of the embedding model with the non-fine-tuned version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2dd1c9-bb66-4d12-afbf-0f527fcca7aa",
   "metadata": {},
   "source": [
    "#### Loading the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb03e91-d904-4ed5-8c24-f31b2c95b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name FacebookAI/xlm-roberta-base. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "xlm_roberta = SentenceTransformer('FacebookAI/xlm-roberta-base')\n",
    "xlm_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92453756-b328-47bc-9014-1e10a6af9d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlm_roberta_ua_distilled = SentenceTransformer('panalexeu/xlm-roberta-ua-distilled')\n",
    "xlm_roberta_ua_distilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c6cf02-cdce-43ae-acc9-61c700ba7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert xlm_roberta[0].get_config_dict() == xlm_roberta_ua_distilled[0].get_config_dict()\n",
    "assert xlm_roberta[1].get_config_dict() == xlm_roberta_ua_distilled[1].get_config_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8502c9-c755-4e5b-bd96-6d679f7695de",
   "metadata": {},
   "source": [
    "#### Evaluation on STS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761730af-db2b-4e3f-be6f-553e985542fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SequentialEvaluator \n",
    "\n",
    "# STS Benchmark (Semantic Textual Similarity Benchmark)\n",
    "en_en_dataset = load_dataset('mteb/sts17-crosslingual-sts', 'en-en', split='test')\n",
    "en_ua_dataset = load_dataset('csv', data_files='../datasets/sts17-en-ua-gpt-4o.csv', split='train') # when loading from csv by default train split is assigned\n",
    "ua_ua_dataset = load_dataset('csv', data_files='../datasets/sts17-ua-ua-gpt-4o.csv', split='train')  # when loading from csv by default train split is assigned\n",
    "\n",
    "# From documentation: Evaluate a model based on the similarity of the embeddings by calculating the Spearman and Pearson rank correlation in comparison to the gold standard labels. \n",
    "en_en_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_en_dataset['sentence1'],\n",
    "    sentences2=en_en_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_en_dataset['score']],  # normalizing to score from to 1\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-en',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "en_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=en_ua_dataset['sentence1'],\n",
    "    sentences2=en_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in en_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-en-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "ua_ua_eval = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=ua_ua_dataset['sentence1'],\n",
    "    sentences2=ua_ua_dataset['sentence2'],\n",
    "    scores=[score / 5.0 for score in ua_ua_dataset['score']],\n",
    "    show_progress_bar=False,\n",
    "    name='sts17-ua-ua',\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Composing evaluators in one chain! \n",
    "evaluator = SequentialEvaluator([en_en_eval, en_ua_eval, ua_ua_eval]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206a3a6-e662-4715-9afe-189efc3bd092",
   "metadata": {},
   "source": [
    "**Original** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8121c4c4-d1a7-4a9f-8f0a-df157093037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_model_preparation_time': 0.0017,\n",
       " 'eval_sts17-en-en_pearson_cosine': 0.36110322291820246,\n",
       " 'eval_sts17-en-en_spearman_cosine': 0.5217129934278466,\n",
       " 'eval_sts17-en-ua_pearson_cosine': 0.12805525703810633,\n",
       " 'eval_sts17-en-ua_spearman_cosine': 0.13454840278964744,\n",
       " 'eval_sts17-ua-ua_pearson_cosine': 0.302438933599461,\n",
       " 'eval_sts17-ua-ua_spearman_cosine': 0.4151725913805182,\n",
       " 'eval_sequential_score': 0.4151725913805182,\n",
       " 'eval_runtime': 2.0318,\n",
       " 'eval_samples_per_second': 0.0,\n",
       " 'eval_steps_per_second': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "SentenceTransformerTrainer(\n",
    "    model=xlm_roberta,\n",
    "    evaluator=evaluator\n",
    ").evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb427c7-b582-49e8-8e8e-9a25d768bc77",
   "metadata": {},
   "source": [
    "**Distilled and fine-tuned** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f99fdbe8-9090-4127-9b78-e20e435bbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_model_preparation_time': 0.0019,\n",
       " 'eval_sts17-en-en_pearson_cosine': 0.5273566734944571,\n",
       " 'eval_sts17-en-en_spearman_cosine': 0.5630721403406446,\n",
       " 'eval_sts17-en-ua_pearson_cosine': 0.36821995782862005,\n",
       " 'eval_sts17-en-ua_spearman_cosine': 0.3551228317268819,\n",
       " 'eval_sts17-ua-ua_pearson_cosine': 0.4831296189234964,\n",
       " 'eval_sts17-ua-ua_spearman_cosine': 0.5271830395192819,\n",
       " 'eval_sequential_score': 0.5271830395192819,\n",
       " 'eval_runtime': 1.788,\n",
       " 'eval_samples_per_second': 0.0,\n",
       " 'eval_steps_per_second': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer \n",
    "\n",
    "SentenceTransformerTrainer(\n",
    "    model=xlm_roberta_ua_distilled,\n",
    "    evaluator=evaluator\n",
    ").evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc4afff-9996-44ea-9435-40b04916beb8",
   "metadata": {},
   "source": [
    "#### Simple small test on quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cce7ada-bf00-4fed-99d3-e55b9db9eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    \"An idiot admires complexity, a genius admires simplicity.\",          # English\n",
    "    \"Ідіот захоплюється складністю, геній — простотою.\",                  # Ukrainian\n",
    "]\n",
    "\n",
    "quotes_antonyms = [\n",
    "    \"Hello, World!\",\n",
    "    \"Прощавай, Місяць.\"\n",
    "]\n",
    "\n",
    "# to check zero-shot crosslingual transfer effect \n",
    "quotes_extended = quotes + [\n",
    "    \"Идиот восхищается сложностью, гений — простотой.\",                   # Russian\n",
    "    \"Ідыёт захапляецца складанасцю, геній — прастатой.\",                  # Belarusian\n",
    "    \"Идиот се възхищава на сложността, гений — на простотата.\"            # Bulgarian\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a4b48-90aa-459c-945b-bf2801c32b12",
   "metadata": {},
   "source": [
    "**Close quotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34e16f14-964d-4ca8-8a15-c25ecd648ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9967],\n",
       "        [0.9967, 1.0000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta.encode(quotes)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a64b4f5-6959-4dba-a090-368ecf75f053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9022],\n",
       "        [0.9022, 1.0000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e7b445-5c78-455a-affe-9447a6ce7dc8",
   "metadata": {},
   "source": [
    "**Antonyms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3f406ee-1022-4762-bd0c-2f0377d2691e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9867],\n",
       "        [0.9867, 1.0000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta.encode(quotes_antonyms)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "320aeadb-fba2-4567-b336-41559dfbebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9172],\n",
       "        [0.9172, 1.0000]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes_antonyms)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9e7fb-debd-496b-9640-43351acc6d89",
   "metadata": {},
   "source": [
    "**Zero-shot cross-lingual transfer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2dd7577-ff74-431a-a28d-57fbbeccf675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9967, 0.9970, 0.9958, 0.9964],\n",
       "        [0.9967, 1.0000, 0.9983, 0.9971, 0.9978],\n",
       "        [0.9970, 0.9983, 1.0000, 0.9970, 0.9987],\n",
       "        [0.9958, 0.9971, 0.9970, 1.0000, 0.9964],\n",
       "        [0.9964, 0.9978, 0.9987, 0.9964, 1.0000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta.encode(quotes_extended)\n",
    "xlm_roberta.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54608e64-d595-4c4a-a66e-56460a90f651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.9022, 0.9028, 0.7964, 0.9064],\n",
       "        [0.9022, 1.0000, 0.9646, 0.9340, 0.9511],\n",
       "        [0.9028, 0.9646, 1.0000, 0.8918, 0.9886],\n",
       "        [0.7964, 0.9340, 0.8918, 1.0000, 0.8647],\n",
       "        [0.9064, 0.9511, 0.9886, 0.8647, 1.0000]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = xlm_roberta_ua_distilled.encode(quotes_extended)\n",
    "xlm_roberta_ua_distilled.similarity(embeds, embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e515dc-c2ba-4cc2-aa66-49ce3c1ffcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed_ua_base",
   "language": "python",
   "name": "embed_ua_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
